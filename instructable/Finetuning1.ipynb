{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/rsaran/extracted_ideas/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[1;32m      5\u001b[0m directory \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/rsaran/extracted_ideas/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 6\u001b[0m files \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m files:\n\u001b[1;32m      9\u001b[0m     file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(directory, file)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/rsaran/extracted_ideas/'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "\n",
    "directory = \"/Users/rsaran/extracted_ideas/\"\n",
    "files = os.listdir(directory)\n",
    "\n",
    "for file in files:\n",
    "    file_path = os.path.join(directory, file)\n",
    "    try:\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "            print(f.read())\n",
    "            break\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {file}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample output format:\n",
      "{'text_input': 'Clear nail polish, Black sharpie, Nail polish in a color of your choice, A needle', 'output': {'description': 'This project allows you to create custom Rebel Alliance earbuds to show your allegiance to the Rebel cause in the Star Wars universe.', 'steps': ['Draw the Rebel Alliance symbol on the back of the earbuds using a black sharpie, being as precise as possible.', 'Carefully apply nail polish (in your chosen color) over the sharpie design using a needle.', 'Allow the colored nail polish to dry completely, then cover the entire back of the earbud with a coat of clear nail polish to seal the design and prevent chipping.', 'Enjoy your custom Rebel Alliance earbuds by listening to Star Wars music.']}}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "items = []\n",
    "directory = \"/Users/rsaran/extracted_ideas/\"\n",
    "files = os.listdir(directory)\n",
    "\n",
    "for file in files:\n",
    "    try:\n",
    "        with open(os.path.join(directory, file), 'r', encoding='utf-8') as f:\n",
    "            content = json.load(f)\n",
    "            items.append({\n",
    "                \"text_input\": \", \".join(content[0]['materials_required']),\n",
    "                \"output\": {\n",
    "                    \"description\": content[0]['description'],\n",
    "                    \"steps\": content[0]['steps']\n",
    "                }\n",
    "            })\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file}: {e}\")\n",
    "        continue\n",
    "\n",
    "    break\n",
    "\n",
    "df = pd.DataFrame(items)\n",
    "df.to_csv('save.csv', index=False)\n",
    "\n",
    "# Verify the output\n",
    "if items:\n",
    "    print(\"Sample output format:\")\n",
    "    print(df.iloc[0].to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved existing collection: ideas-collection\n",
      "Skipping row 13 due to invalid text_input\n",
      "Skipping row 21 due to invalid text_input\n",
      "Skipping row 30 due to invalid text_input\n",
      "Skipping row 45 due to invalid text_input\n",
      "Skipping row 60 due to invalid text_input\n",
      "Skipping row 63 due to invalid text_input\n",
      "Skipping row 65 due to invalid text_input\n",
      "Skipping row 120 due to invalid text_input\n",
      "Skipping row 165 due to invalid text_input\n",
      "Skipping row 169 due to invalid text_input\n",
      "Skipping row 173 due to invalid text_input\n",
      "Skipping row 174 due to invalid text_input\n",
      "Skipping row 186 due to invalid text_input\n",
      "Skipping row 205 due to invalid text_input\n",
      "Skipping row 222 due to invalid text_input\n",
      "Skipping row 226 due to invalid text_input\n",
      "Skipping row 240 due to invalid text_input\n",
      "Skipping row 269 due to invalid text_input\n",
      "Skipping row 272 due to invalid text_input\n",
      "Skipping row 277 due to invalid text_input\n",
      "Skipping row 291 due to invalid text_input\n",
      "Skipping row 293 due to invalid text_input\n",
      "Skipping row 306 due to invalid text_input\n",
      "Skipping row 310 due to invalid text_input\n",
      "Skipping row 322 due to invalid text_input\n",
      "Skipping row 334 due to invalid text_input\n",
      "Skipping row 379 due to invalid text_input\n",
      "Skipping row 385 due to invalid text_input\n",
      "Skipping row 393 due to invalid text_input\n",
      "Skipping row 400 due to invalid text_input\n",
      "Skipping row 419 due to invalid text_input\n",
      "Skipping row 424 due to invalid text_input\n",
      "Skipping row 429 due to invalid text_input\n",
      "Skipping row 443 due to invalid text_input\n",
      "Skipping row 444 due to invalid text_input\n",
      "Skipping row 448 due to invalid text_input\n",
      "Skipping row 452 due to invalid text_input\n",
      "Skipping row 461 due to invalid text_input\n",
      "Skipping row 462 due to invalid text_input\n",
      "Skipping row 552 due to invalid text_input\n",
      "Skipping row 557 due to invalid text_input\n",
      "Skipping row 558 due to invalid text_input\n",
      "Skipping row 574 due to invalid text_input\n",
      "Skipping row 583 due to invalid text_input\n",
      "Skipping row 588 due to invalid text_input\n",
      "Skipping row 592 due to invalid text_input\n",
      "Skipping row 598 due to invalid text_input\n",
      "Skipping row 610 due to invalid text_input\n",
      "Skipping row 663 due to invalid text_input\n",
      "Skipping row 665 due to invalid text_input\n",
      "Skipping row 687 due to invalid text_input\n",
      "Skipping row 702 due to invalid text_input\n",
      "Skipping row 720 due to invalid text_input\n",
      "Skipping row 730 due to invalid text_input\n",
      "Skipping row 746 due to invalid text_input\n",
      "Skipping row 753 due to invalid text_input\n",
      "Skipping row 779 due to invalid text_input\n",
      "Skipping row 781 due to invalid text_input\n",
      "Skipping row 785 due to invalid text_input\n",
      "Skipping row 789 due to invalid text_input\n",
      "Skipping row 800 due to invalid text_input\n",
      "Skipping row 828 due to invalid text_input\n",
      "Skipping row 845 due to invalid text_input\n",
      "Skipping row 846 due to invalid output format\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "import json\n",
    "import pandas as pd\n",
    "from typing import List, Dict\n",
    "\n",
    "def setup_chroma_collection(collection_name: str = \"ideas-collection\") -> chromadb.Collection:\n",
    "    \"\"\"Initialize ChromaDB client and create/get collection.\"\"\"\n",
    "    client = chromadb.Client()\n",
    "    \n",
    "    try:\n",
    "        collection = client.get_collection(collection_name)\n",
    "        print(f\"Retrieved existing collection: {collection_name}\")\n",
    "    except:\n",
    "        collection = client.create_collection(collection_name)\n",
    "        print(f\"Created new collection: {collection_name}\")\n",
    "    \n",
    "    return collection\n",
    "\n",
    "def load_data_from_csv(filepath: str = 'save.csv') -> pd.DataFrame:\n",
    "    \"\"\"Load data from CSV file.\"\"\"\n",
    "    return pd.DataFrame(pd.read_csv(filepath))\n",
    "\n",
    "def prepare_documents(df: pd.DataFrame) -> tuple[List[str], List[Dict], List[str]]:\n",
    "    \"\"\"Prepare documents, metadata, and IDs for ChromaDB while skipping invalid rows.\"\"\"\n",
    "    documents = []\n",
    "    metadatas = []\n",
    "    ids = []\n",
    "\n",
    "    for i, row in df.iterrows():\n",
    "        text = row.get('text_input', '')\n",
    "        output = row.get('output', {})\n",
    "\n",
    "        # Skip invalid entries\n",
    "        if not isinstance(text, str) or not text.strip():\n",
    "            print(f\"Skipping row {i} due to invalid text_input\")\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            metadata = json.loads(output) if isinstance(output, str) else output\n",
    "            if not isinstance(metadata, dict):\n",
    "                raise ValueError\n",
    "        except (json.JSONDecodeError, ValueError):\n",
    "            print(f\"Skipping row {i} due to invalid output format\")\n",
    "            continue\n",
    "\n",
    "        documents.append(text)\n",
    "        metadatas.append(metadata)\n",
    "        ids.append(f\"doc_{len(ids)}\")\n",
    "\n",
    "    return documents, metadatas, ids\n",
    "\n",
    "def add_to_chroma(collection: chromadb.Collection, \n",
    "                  documents: List[str], \n",
    "                  metadatas: List[Dict], \n",
    "                  ids: List[str]) -> None:\n",
    "    \"\"\"Add documents to ChromaDB collection.\"\"\"\n",
    "    collection.add(\n",
    "        documents=documents,\n",
    "        metadatas=metadatas,\n",
    "        ids=ids\n",
    "    )\n",
    "    print(f\"Added {len(documents)} documents to the collection\")\n",
    "\n",
    "def query_chroma(collection: chromadb.Collection, \n",
    "                 query_text: str, \n",
    "                 n_results: int = 2) -> Dict:\n",
    "    \"\"\"Query the ChromaDB collection.\"\"\"\n",
    "    results = collection.query(\n",
    "        query_texts=[query_text],\n",
    "        n_results=n_results\n",
    "    )\n",
    "    return results\n",
    "\n",
    "def main():\n",
    "    collection = setup_chroma_collection()\n",
    "    \n",
    "    df = load_data_from_csv()\n",
    "\n",
    "    documents, metadatas, ids = prepare_documents(df)\n",
    "\n",
    "    add_to_chroma(collection, documents, metadatas, ids)\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Sample query text\"\n",
    "results = query_chroma(collection, query)\n",
    "\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
